{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a671d21-2480-4b9b-9be1-c31f94ee912a",
   "metadata": {},
   "source": [
    "# LOCA2 30-year Moving Mean Annual Max Temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf373a4-9794-4ddf-a5aa-aafc395e58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Library Calls.\n",
    "#\n",
    "\n",
    "# loading numpy\n",
    "\n",
    "import numpy             as np\n",
    "\n",
    "# loading matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading xarray\n",
    "\n",
    "import xarray            as xr\n",
    "\n",
    "# Loading pandas\n",
    "\n",
    "import pandas            as pd\n",
    "\n",
    "\n",
    "\n",
    "import subprocess as subprocess\n",
    "\n",
    "\n",
    "\n",
    "def geo_idx(dd, dd_array):\n",
    "\n",
    "    geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "    return geo_idx\n",
    " \n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad579283-7a18-48d0-ae9f-68d6444a0b3e",
   "metadata": {},
   "source": [
    "##  File Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993baf1-e898-4c48-8b10-e10dd4ec1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# File Control\n",
    "#\n",
    "\n",
    "Original_File_Prefix = \"LOCA2-CONUS-ANNUAL_MEAN\"\n",
    "Final_File_Prefix    = \"LOCA2-CONUS-ANNUAL30YRUNMEAN_MEAN\"\n",
    "\n",
    "variable    = \"tasmax\"\n",
    "\n",
    "tempfile    = \"./\" + variable + \"_tempfile.nc\"\n",
    "memberfile  = \"./\" + variable + \"_model_member.nc\"\n",
    "\n",
    "cell_method = \"time: maximum within days  time: mean within years  time: mean over 30 years \"\n",
    "\n",
    "target_rank =  \"1\"\n",
    "rank00      = \"01\"\n",
    "\n",
    "root_directory        = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Annual\"\n",
    "root_url              = \"http://kyrill.ias.sdsmt.edu:8080/thredds/dodsC/LOCA2/Climate_CONUS/Annual\"\n",
    "\n",
    "loca2_inventory_file  = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Original_CONUS/LOCA2_Model_Member_Available_List.csv\"\n",
    "loca2_complete_file   = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Original_CONUS/LOCA2_Model_Member_Complete_List.csv\"\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a0503-94b1-4c5a-a0fe-c98ccbb56990",
   "metadata": {},
   "source": [
    "## Inventories and Lookup Tables\n",
    "### All Potential Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55407694-92d9-401f-9327-749aa795de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Inventory and Model/Member Lookup Table for all Possible Ensembles\n",
    "#\n",
    "\n",
    "\n",
    "loca2_complete_list = pd.read_csv(filepath_or_buffer = loca2_complete_file)\n",
    "\n",
    "modelsc               = loca2_complete_list[         \"Model\"].values\n",
    "membersc              = loca2_complete_list[        \"Member\"].values\n",
    "model_membersc        = loca2_complete_list[  \"Model_Member\"].values\n",
    "\n",
    "model_member_key0 = np.array(modelsc+\".\"+membersc, dtype=\"str\")\n",
    "model_member_key =  np.array([\"NULL\"], dtype=\"str\")\n",
    "\n",
    "model_members_to_save = np.append(0,model_membersc)\n",
    "\n",
    "model_member_key = np.append(model_member_key,model_member_key0)\n",
    "\n",
    "\n",
    "model_member_key    = xr.DataArray(model_member_key, \n",
    "                                   coords={\"model_member\":model_members_to_save},\n",
    "                                   name  = \"model_member_key\",\n",
    "                                   dims  = [\"model_member\"],\n",
    "                                   attrs = {\"description\" : \"Model and Member Label\",\n",
    "                                              \"long_name\" : \"Model and Member Label\",\n",
    "                                               \"comment1\" :   \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "display(model_member_key)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ffdc9-92ac-4e18-bc58-c870a0f50b84",
   "metadata": {},
   "source": [
    "### All Available Ensembles for Selected Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046bd9b-7af6-45e6-a7bb-b4cfc3597444",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Inventory and Model/Member Lookup Table for all Possible Ensembles\n",
    "#\n",
    "\n",
    "loca2_ensembles_list = pd.read_csv(filepath_or_buffer = loca2_inventory_file)\n",
    "\n",
    "loca2_ensembles_list = loca2_ensembles_list.query(\"Rank == \" + target_rank)\n",
    "\n",
    "models               = loca2_ensembles_list[         \"Model\"].values\n",
    "members              = loca2_ensembles_list[        \"Member\"].values\n",
    "model_members        = loca2_ensembles_list[  \"Model_Member\"].values\n",
    "n_complete_enss      = loca2_ensembles_list[\"n_complete_ens\"].values\n",
    "historical_invs      = loca2_ensembles_list[    \"historical\"].values\n",
    "ssp245_invs          = loca2_ensembles_list[        \"ssp245\"].values\n",
    "ssp370_invs          = loca2_ensembles_list[        \"ssp370\"].values\n",
    "ssp585_invs          = loca2_ensembles_list[        \"ssp585\"].values\n",
    "prec_invs            = loca2_ensembles_list[            \"pr\"].values\n",
    "tmax_invs            = loca2_ensembles_list[        \"tasmax\"].values\n",
    "tmin_invs            = loca2_ensembles_list[        \"tasmin\"].values\n",
    "\n",
    "scenarios            = [\"historical\", \n",
    "                            \"ssp245\", \n",
    "                            \"ssp370\", \n",
    "                            \"ssp585\"]\n",
    "\n",
    "display(loca2_ensembles_list)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7b0ad-dc9a-4a7b-a3ab-1e42e618df93",
   "metadata": {},
   "source": [
    "## Loop for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcba28-84ee-4e83-b114-be1fcf13fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Loop Test\n",
    "#\n",
    "\n",
    "    \n",
    "for scenario in scenarios[1:]:\n",
    "    print(\"# ################################################\")\n",
    "    First = True\n",
    "    for m in range(len(models)-1):\n",
    "        print(\"# ------------------------------------------------\")\n",
    "\n",
    "        model          =          models[m]\n",
    "        member         =         members[m]\n",
    "        model_member   =   model_members[m]\n",
    "\n",
    "        n_complete_ens = n_complete_enss[m]\n",
    "        prec_inv       =       prec_invs[m]\n",
    "        tmax_inv       =       tmax_invs[m]\n",
    "        tmin_inv       =       tmin_invs[m]\n",
    "\n",
    "        model_member_name = np.array([model + \".\" + member], dtype=\"str\")\n",
    "        model_member      = np.array([model_member], dtype=\"int16\").flatten().astype(np.int16)\n",
    "        \n",
    "\n",
    "\n",
    "        model_member = xr.DataArray(data   = model_member.astype(np.int16),\n",
    "                                    coords = {\"model_member\":model_member.astype(np.int16)},\n",
    "                                    name   =  \"model_member\",\n",
    "                                    dims   = [\"model_member\"],\n",
    "                                    attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                              \"long_name\"   : \"Model and Member Code\",\n",
    "                                              \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                              \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "        print(\"# ================================================\")\n",
    "\n",
    "        inventory = loca2_ensembles_list.iloc[m].loc[scenario]\n",
    "        print(\"# \" + str(model_member[0].values).zfill(3) + \" \" + model + \" \" + member + \" \" + scenario + \" \" + inventory)\n",
    "\n",
    "        if (inventory != \"---\"):\n",
    "\n",
    "\n",
    "            if (\"N\" in inventory):\n",
    "\n",
    "\n",
    "\n",
    "                print(\"#  . . . . . . . . . . . . . . . . . . . . . . . .\")\n",
    "\n",
    "                hist_file         = root_directory                            +  \"/\"  + \\\n",
    "                                    \"historical\"                              +  \"/\"  + \\\n",
    "                                    Original_File_Prefix                      + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    \"historical\"                              + \".nc\"  \n",
    "\n",
    "                futr_file         = root_directory                            +  \"/\"  + \\\n",
    "                                    scenario                                  +  \"/\"  + \\\n",
    "                                    Original_File_Prefix                      + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    "\n",
    "                combined_file     = root_directory                            +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    str(model_member[0].values).zfill(3)      + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    " \n",
    "                combined_wc_files = root_directory                            +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"???\"                                     + \"___\" + \\\n",
    "                                    \"*\"                                       + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "\n",
    "                final_merged_file = root_directory                            +  \"/\"  + \\\n",
    "                                    scenario                                  +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"ALLRANK\"+ rank00                         + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "        \n",
    "                ds            = xr.open_dataset(filename_or_obj = futr_file)\n",
    "                time_futr_max = ds[\"time\"].values.max()\n",
    "                time_futr_n   = ds[variable].values.shape\n",
    "                \n",
    "                print(\"#    Max_Orig_Time = \" + str(time_futr_max) + \"      \" + str(time_futr_n) )\n",
    "                \n",
    "                if (First):\n",
    "                    model_member_array = np.array(model_members[m], dtype = \"int16\")\n",
    "                    First              = False\n",
    "                else:\n",
    "                    model_member_array = np.append(model_member_array, model_members[m]).flatten().astype(np.int16)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                cdo_cat_command = \"nohup cdo --no_history -f nc4 -z zip_9  mergetime \"\n",
    "\n",
    "                command_aggregate = cdo_cat_command + hist_file + \" \" + futr_file + \" \" + tempfile\n",
    "                subprocess.run([\"rm -fr \" + tempfile],                             shell = True, check = True)\n",
    "                subprocess.run([command_aggregate],                                shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,time,d,,     \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lon,d,,      \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lat,d,,      \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lon,d,,  \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lat,d,,  \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,time,d,, \" + tempfile], shell = True, check = True)\n",
    " \n",
    "                ds              = xr.open_dataset(filename_or_obj = tempfile)\n",
    "                tasmin0         = ds[variable]\n",
    "        \n",
    "                time_merged_max = ds[\"time\"].values.max()\n",
    "                time_merged_n   = ds[variable].values.shape\n",
    "                \n",
    "                print(\"#   Max_Merge_Time = \" + str(time_merged_max) + \"     \" + str(time_merged_n) )      \n",
    "        \n",
    "                subprocess.run([\"rm -fr \" + tempfile], shell = True, check = True)\n",
    "\n",
    "                tasmin = tasmin0.rolling(time   =   30, \n",
    "                                         center = True).mean().dropna(dim = \"time\", \n",
    "                                                                      how =  \"all\")\n",
    "                \n",
    "                tasmin.name = variable\n",
    "                tasmin.attrs[\"cell_methods\"] = cell_method\n",
    "                \n",
    "                tasmin  = tasmin.expand_dims(dim={\"model_member\" : 1})              \n",
    "\n",
    "                outdata = xr.Dataset(data_vars = {variable       :                        tasmin,\n",
    "                                                  \"model_member\" : model_member.astype(np.int16)},\n",
    "                                     attrs     = {\"scenario\"     :                      scenario})\n",
    "\n",
    "                outdata.to_netcdf(path           =  combined_file, \n",
    "                                  mode           =            'w', \n",
    "                                  format         =      \"NETCDF4\",\n",
    "                                  engine         =     \"h5netcdf\", #\n",
    "                                  unlimited_dims = \"model_member\",\n",
    "                                  encoding       = {variable: {        \"dtype\": \"int16\", \n",
    "                                                                \"scale_factor\":     0.1,\n",
    "                                                                  \"add_offset\":     0.0,                                        \n",
    "                                                                  \"_FillValue\":  -32767}})\n",
    "                \n",
    "                subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncatted -Oh -a _FillValue,lon,d,, \" + combined_file], \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "                subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncatted -Oh -a _FillValue,lat,d,, \" + combined_file], \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "                subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncatted -Oh -a _FillValue,time,d,, \" + combined_file],  \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "                \n",
    "                ds               = xr.open_dataset(filename_or_obj = combined_file)\n",
    "                time_running_max = ds[\"time\"].values.max()\n",
    "                time_running_n   = ds[variable].values.shape\n",
    "                print(\"# Max_Running_Time = \" + str(time_running_max) + \"  \" + str(time_running_n) )                                 \n",
    "                \n",
    "            # end check on avaiable variable\n",
    "        # end check on on avaiable member\n",
    "            \n",
    "    #end loop on model\n",
    "\n",
    "    print(\"# = = = = = = = = = = = = = = = = = = = = = = = = \") \n",
    "    \n",
    "    model_member = xr.DataArray(data   = model_member_array.astype(np.int16),\n",
    "                                name   =  \"model_member\",\n",
    "                                dims   = [\"model_member\"],\n",
    "                                attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                          \"long_name\"   : \"Model and Member Code\",\n",
    "                                          \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                          \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "    model_member_ds = xr.Dataset(data_vars = {\"model_member\" : model_member},\n",
    "                                 attrs     = {\"scenario\"     :     scenario})\n",
    "    \n",
    "    model_member_ds.to_netcdf(path            =   memberfile, \n",
    "                               mode           =           'w', \n",
    "                               format         =     \"NETCDF4\",\n",
    "                               engine         =    \"h5netcdf\", #\n",
    "                               unlimited_dims = \"model_member\")  \n",
    "        \n",
    "    cdo_cat_command = \"nohup cdo --no_history -f nc4 -z zip_9 cat \"\n",
    "    nco_cat_command = \"nohup ncecat -M -u model_member \"\n",
    "    command_aggregate = cdo_cat_command +combined_wc_files + \" \" + tempfile    \n",
    "    print(\"# Final Aggregation\")\n",
    "    subprocess.run([\"rm -fr \" + final_merged_file + \" \" + tempfile + \" 2_\" + tempfile], \n",
    "                   shell = True, \n",
    "                   check = True)    \n",
    "    subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && \" + command_aggregate], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# Files Concatenated\")\n",
    "\n",
    "    subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncks -C -O -x -v model_member \" + tempfile + \" \" + final_merged_file], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# dimension dropped\")\n",
    "    subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncks -h -A \"+ memberfile + \" \" + final_merged_file], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    ds               = xr.open_dataset(filename_or_obj = final_merged_file)\n",
    "    time_running_max = ds[\"time\"].values.max()\n",
    "    time_running_n   = ds[variable].values.shape\n",
    "    print(\"#     Max_Ens_Time = \" + str(time_running_max) + \" \" + str(time_running_n) )  \n",
    "    print(\"# dimension swapped\")\n",
    "    subprocess.run([\"rm -fr  \" + tempfile + \" 2_\" + tempfile + \" \" + combined_wc_files], \n",
    "                   shell = True, \n",
    "                   check = True) \n",
    "\n",
    "# end loop on scenario\n",
    "                \n",
    "print(\"# ================================================\")\n",
    "print(\"end processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5237d-f41d-45e5-8507-9b6ce3af1107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094c6cd9-732c-4dd0-a889-5ab5e1004edc",
   "metadata": {},
   "source": [
    "# Version History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9fa46-4b84-4a54-bfd7-417b132bd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#\n",
    "# Loading Version Information\n",
    "#\n",
    "\n",
    "%load_ext version_information\n",
    "%version_information version_information numpy, matplotlib, xarray, pandas, cartopy, metpy\n",
    "\n",
    "#\n",
    "################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
