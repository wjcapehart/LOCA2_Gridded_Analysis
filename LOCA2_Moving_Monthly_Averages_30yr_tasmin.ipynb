{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a671d21-2480-4b9b-9be1-c31f94ee912a",
   "metadata": {},
   "source": [
    "# LOCA2 30-year Moving Mean Annual Min Temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf373a4-9794-4ddf-a5aa-aafc395e58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Library Calls.\n",
    "#\n",
    "\n",
    "# loading numpy\n",
    "\n",
    "import numpy             as np\n",
    "\n",
    "# loading matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading xarray\n",
    "\n",
    "import xarray            as xr\n",
    "\n",
    "# Loading pandas\n",
    "\n",
    "import pandas            as pd\n",
    "\n",
    "import os as os\n",
    "\n",
    "import subprocess as subprocess\n",
    "\n",
    "def geo_idx(dd, dd_array):\n",
    "\n",
    "    geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "    return geo_idx\n",
    " \n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad579283-7a18-48d0-ae9f-68d6444a0b3e",
   "metadata": {},
   "source": [
    "##  File Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8993baf1-e898-4c48-8b10-e10dd4ec1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# File Control\n",
    "#\n",
    "\n",
    "Original_File_Prefix = \"LOCA2-CONUS-MONTHLY_MEAN\"\n",
    "Final_File_Prefix    = \"LOCA2-CONUS-ANNUAL30YRUNMEAN_MONTHLYMEAN\"\n",
    "\n",
    "variable    = \"tasmin\"\n",
    "\n",
    "tempfile    = \"./\" + variable + \"_tempfile.nc\"\n",
    "memberfile  = \"./\" + variable + \"_model_member.nc\"\n",
    "\n",
    "local_hdf_string = \"export HDF5_USE_FILE_LOCKING=FALSE && \"\n",
    "local_hdf_string = \" \"\n",
    "\n",
    "cell_method    = \"time: minimum within days  time: mean within months  time: mean over 30 years \"\n",
    "cell_methodsdv = \"time: mean over months   time: stdev over 30 years \"\n",
    "\n",
    "target_rank =  \"1\"\n",
    "rank00      = \"01\"\n",
    "\n",
    "root_directory        = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly\"\n",
    "root_url              = \"http://kyrill.ias.sdsmt.edu:8080/thredds/dodsC/LOCA2/Climate_CONUS/Monthly\"\n",
    "\n",
    "loca2_inventory_file  = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/LOCA2_Model_Member_Available_List.csv\"\n",
    "loca2_complete_file   = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/LOCA2_Model_Member_Complete_List.csv\"\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a0503-94b1-4c5a-a0fe-c98ccbb56990",
   "metadata": {},
   "source": [
    "## Inventories and Lookup Tables\n",
    "### All Potential Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55407694-92d9-401f-9327-749aa795de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'model_member_key' (model_member: 109)> Size: 10kB\n",
      "array(['NULL', 'GFDL-ESM4.r1i1p1f1', 'BCC-CSM2-MR.r1i1p1f1',\n",
      "       'GFDL-CM4.r1i1p1f1', 'CNRM-CM6-1.r1i1p1f2', 'TaiESM1.r1i1p1f1',\n",
      "       'CNRM-ESM2-1.r1i1p1f2', 'CNRM-CM6-1-HR.r1i1p1f2',\n",
      "       'INM-CM4-8.r1i1p1f1', 'MIROC6.r1i1p1f1', 'MRI-ESM2-0.r5i1p1f1',\n",
      "       'INM-CM5-0.r4i1p1f1', 'HadGEM3-GC31-MM.r2i1p1f3',\n",
      "       'NorESM2-LM.r2i1p1f1', 'FGOALS-g3.r3i1p1f1',\n",
      "       'ACCESS-ESM1-5.r1i1p1f1', 'HadGEM3-GC31-LL.r3i1p1f3',\n",
      "       'EC-Earth3.r2i1p1f1', 'NorESM2-MM.r2i1p1f1', 'CanESM5.r1i1p1f1',\n",
      "       'ACCESS-CM2.r1i1p1f1', 'CESM2-LENS.r4i1p1f1',\n",
      "       'IPSL-CM6A-LR.r3i1p1f1', 'EC-Earth3-Veg.r4i1p1f1',\n",
      "       'KACE-1-0-G.r2i1p1f1', 'MPI-ESM1-2-HR.r10i1p1f1',\n",
      "       'MPI-ESM1-2-LR.r10i1p1f1', 'AWI-CM-1-1-MR.r1i1p1f1',\n",
      "       'INM-CM5-0.r3i1p1f1', 'FGOALS-g3.r1i1p1f1', 'MRI-ESM2-0.r1i1p1f1',\n",
      "       'NorESM2-LM.r3i1p1f1', 'HadGEM3-GC31-MM.r1i1p1f3',\n",
      "       'MIROC6.r2i1p1f1', 'ACCESS-ESM1-5.r5i1p1f1', 'ACCESS-CM2.r3i1p1f1',\n",
      "       'EC-Earth3.r4i1p1f1', 'CESM2-LENS.r6i1p1f1', 'NorESM2-MM.r1i1p1f1',\n",
      "       'EC-Earth3-Veg.r3i1p1f1', 'HadGEM3-GC31-LL.r2i1p1f3',\n",
      "       'KACE-1-0-G.r1i1p1f1', 'IPSL-CM6A-LR.r2i1p1f1',\n",
      "       'MPI-ESM1-2-HR.r2i1p1f1', 'CanESM5.r4i1p1f1',\n",
      "       'AWI-CM-1-1-MR.r2i1p1f1', 'MPI-ESM1-2-LR.r3i1p1f1',\n",
      "...\n",
      "       'MRI-ESM2-0.r3i1p1f1', 'CESM2-LENS.r3i1p1f1', 'MIROC6.r5i1p1f1',\n",
      "       'ACCESS-ESM1-5.r3i1p1f1', 'EC-Earth3.r1i1p1f1',\n",
      "       'IPSL-CM6A-LR.r5i1p1f1', 'EC-Earth3-Veg.r1i1p1f1',\n",
      "       'MPI-ESM1-2-HR.r1i1p1f1', 'CanESM5.r2i1p1f1',\n",
      "       'MPI-ESM1-2-LR.r7i1p1f1', 'AWI-CM-1-1-MR.r5i1p1f1',\n",
      "       'CESM2-LENS.r5i1p1f1', 'MIROC6.r4i1p1f1', 'ACCESS-ESM1-5.r4i1p1f1',\n",
      "       'IPSL-CM6A-LR.r9i1p1f1', 'MRI-ESM2-0.r4i1p1f1',\n",
      "       'EC-Earth3-Veg.r2i1p1f1', 'INM-CM5-0.r2i1p1f1', 'CanESM5.r5i1p1f1',\n",
      "       'MPI-ESM1-2-HR.r3i1p1f1', 'MPI-ESM1-2-LR.r5i1p1f1',\n",
      "       'AWI-CM-1-1-MR.r3i1p1f1', 'CESM2-LENS.r1i1p1f1',\n",
      "       'IPSL-CM6A-LR.r1i1p1f1', 'MPI-ESM1-2-HR.r5i1p1f1',\n",
      "       'CanESM5.r7i1p1f1', 'MPI-ESM1-2-LR.r2i1p1f1',\n",
      "       'CESM2-LENS.r10i1p1f1', 'IPSL-CM6A-LR.r10i1p1f1',\n",
      "       'MPI-ESM1-2-HR.r9i1p1f1', 'CanESM5.r3i1p1f1',\n",
      "       'MPI-ESM1-2-LR.r6i1p1f1', 'CESM2-LENS.r2i1p1f1',\n",
      "       'IPSL-CM6A-LR.r4i1p1f1', 'MPI-ESM1-2-HR.r4i1p1f1',\n",
      "       'MPI-ESM1-2-LR.r1i1p1f1', 'CESM2-LENS.r9i1p1f1',\n",
      "       'IPSL-CM6A-LR.r6i1p1f1', 'MPI-ESM1-2-HR.r8i1p1f1',\n",
      "       'MPI-ESM1-2-LR.r4i1p1f1', 'CESM2-LENS.r8i1p1f1',\n",
      "       'IPSL-CM6A-LR.r7i1p1f1', 'MPI-ESM1-2-HR.r7i1p1f1'], dtype='<U24')\n",
      "Coordinates:\n",
      "  * model_member  (model_member) int64 872B 0 1 2 3 4 5 ... 104 105 106 107 108\n",
      "Attributes:\n",
      "    description:  Model and Member Label\n",
      "    long_name:    Model and Member Label\n",
      "    comment1:     LUT Indexing Starts at 0\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Inventory and Model/Member Lookup Table for all Possible Ensembles\n",
    "#\n",
    "\n",
    "\n",
    "loca2_complete_list = pd.read_csv(filepath_or_buffer = loca2_complete_file)\n",
    "\n",
    "modelsc               = loca2_complete_list[         \"Model\"].values\n",
    "membersc              = loca2_complete_list[        \"Member\"].values\n",
    "model_membersc        = loca2_complete_list[  \"Model_Member\"].values\n",
    "\n",
    "model_member_key0 = np.array(modelsc+\".\"+membersc, dtype=\"str\")\n",
    "model_member_key =  np.array([\"NULL\"], dtype=\"str\")\n",
    "\n",
    "model_members_to_save = np.append(0,model_membersc)\n",
    "\n",
    "model_member_key = np.append(model_member_key,model_member_key0)\n",
    "\n",
    "\n",
    "model_member_key    = xr.DataArray(model_member_key, \n",
    "                                   coords={\"model_member\":model_members_to_save},\n",
    "                                   name  = \"model_member_key\",\n",
    "                                   dims  = [\"model_member\"],\n",
    "                                   attrs = {\"description\" : \"Model and Member Label\",\n",
    "                                              \"long_name\" : \"Model and Member Label\",\n",
    "                                               \"comment1\" :   \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "print(model_member_key)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ffdc9-92ac-4e18-bc58-c870a0f50b84",
   "metadata": {},
   "source": [
    "### All Available Ensembles for Selected Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c046bd9b-7af6-45e6-a7bb-b4cfc3597444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model_Member            Model     Member  Var  Season  Stat   NetError  \\\n",
      "0              1        GFDL-ESM4   r1i1p1f1  All  Annual  Both   6.152235   \n",
      "1              2      BCC-CSM2-MR   r1i1p1f1  All  Annual  Both   6.357673   \n",
      "2              3         GFDL-CM4   r1i1p1f1  All  Annual  Both   6.498461   \n",
      "3              4       CNRM-CM6-1   r1i1p1f2  All  Annual  Both   6.513064   \n",
      "4              5          TaiESM1   r1i1p1f1  All  Annual  Both   6.658829   \n",
      "5              6      CNRM-ESM2-1   r1i1p1f2  All  Annual  Both   6.681317   \n",
      "6              7    CNRM-CM6-1-HR   r1i1p1f2  All  Annual  Both   6.990708   \n",
      "7              8        INM-CM4-8   r1i1p1f1  All  Annual  Both   7.238094   \n",
      "8              9           MIROC6   r1i1p1f1  All  Annual  Both   8.165782   \n",
      "9             10       MRI-ESM2-0   r5i1p1f1  All  Annual  Both   9.399468   \n",
      "10            11        INM-CM5-0   r4i1p1f1  All  Annual  Both   9.595832   \n",
      "11            12  HadGEM3-GC31-MM   r2i1p1f3  All  Annual  Both   9.730879   \n",
      "12            13       NorESM2-LM   r2i1p1f1  All  Annual  Both   9.902020   \n",
      "13            14        FGOALS-g3   r3i1p1f1  All  Annual  Both   9.930760   \n",
      "14            15    ACCESS-ESM1-5   r1i1p1f1  All  Annual  Both  10.086129   \n",
      "15            16  HadGEM3-GC31-LL   r3i1p1f3  All  Annual  Both  10.124722   \n",
      "16            17        EC-Earth3   r2i1p1f1  All  Annual  Both  10.146428   \n",
      "17            18       NorESM2-MM   r2i1p1f1  All  Annual  Both  10.246951   \n",
      "18            19          CanESM5   r1i1p1f1  All  Annual  Both  10.595282   \n",
      "19            20       ACCESS-CM2   r1i1p1f1  All  Annual  Both  10.657392   \n",
      "20            21       CESM2-LENS   r4i1p1f1  All  Annual  Both  10.875201   \n",
      "21            22     IPSL-CM6A-LR   r3i1p1f1  All  Annual  Both  10.900917   \n",
      "22            23    EC-Earth3-Veg   r4i1p1f1  All  Annual  Both  10.940750   \n",
      "23            24       KACE-1-0-G   r2i1p1f1  All  Annual  Both  11.248111   \n",
      "24            25    MPI-ESM1-2-HR  r10i1p1f1  All  Annual  Both  11.568492   \n",
      "25            26    MPI-ESM1-2-LR  r10i1p1f1  All  Annual  Both  11.950732   \n",
      "26            27    AWI-CM-1-1-MR   r1i1p1f1  All  Annual  Both  11.980818   \n",
      "\n",
      "    Rank historical ssp245 ssp370 ssp585 tasmax tasmin    pr  n_complete_ens  \\\n",
      "0      1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "1      1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "2      1        XNP    XNP    ---    XNP   H2-5   H2-5  H2-5               3   \n",
      "3      1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "4      1        XNP    XNP    XNP    ---   H23-   H23-  H23-               3   \n",
      "5      1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "6      1        XNP    ---    ---    XNP   H--5   H--5  H--5               2   \n",
      "7      1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "8      1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "9      1        XNP    ---    XNP    ---   H-3-   H-3-  H-3-               2   \n",
      "10     1        XNP    ---    XNP    ---   H-3-   H-3-  H-3-               2   \n",
      "11     1        XNP    ---    ---    XNP   H--5   H--5  H--5               2   \n",
      "12     1        XNP    XNP    ---    ---   H2--   H2--  H2--               2   \n",
      "13     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "14     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "15     1        XNP    ---    ---    XNP   H--5   H--5  H--5               2   \n",
      "16     1        XNP    XNP    ---    ---   H2--   H2--  H2--               2   \n",
      "17     1        XNP    XNP    ---    ---   H2--   H2--  H2--               2   \n",
      "18     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "19     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "20     1        XNP    ---    XNP    ---   H-3-   H-3-  H-3-               2   \n",
      "21     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "22     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "23     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "24     1        XNP    ---    XNP    ---   H-3-   H-3-  H-3-               2   \n",
      "25     1        XNP    XNP    XNP    --P   H23-   H23-  H235               3   \n",
      "26     1        XNP    XNP    XNP    XNP   H235   H235  H235               4   \n",
      "\n",
      "    n_avail_ens  \n",
      "0             4  \n",
      "1             4  \n",
      "2             3  \n",
      "3             4  \n",
      "4             3  \n",
      "5             4  \n",
      "6             2  \n",
      "7             4  \n",
      "8             4  \n",
      "9             2  \n",
      "10            2  \n",
      "11            2  \n",
      "12            2  \n",
      "13            4  \n",
      "14            4  \n",
      "15            2  \n",
      "16            2  \n",
      "17            2  \n",
      "18            4  \n",
      "19            4  \n",
      "20            2  \n",
      "21            4  \n",
      "22            4  \n",
      "23            4  \n",
      "24            2  \n",
      "25            4  \n",
      "26            4  \n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Inventory and Model/Member Lookup Table for all Possible Ensembles\n",
    "#\n",
    "\n",
    "loca2_ensembles_list = pd.read_csv(filepath_or_buffer = loca2_inventory_file)\n",
    "\n",
    "loca2_ensembles_list = loca2_ensembles_list.query(\"Rank == \" + target_rank)\n",
    "\n",
    "models               = loca2_ensembles_list[         \"Model\"].values\n",
    "members              = loca2_ensembles_list[        \"Member\"].values\n",
    "model_members        = loca2_ensembles_list[  \"Model_Member\"].values\n",
    "n_complete_enss      = loca2_ensembles_list[\"n_complete_ens\"].values\n",
    "historical_invs      = loca2_ensembles_list[    \"historical\"].values\n",
    "ssp245_invs          = loca2_ensembles_list[        \"ssp245\"].values\n",
    "ssp370_invs          = loca2_ensembles_list[        \"ssp370\"].values\n",
    "ssp585_invs          = loca2_ensembles_list[        \"ssp585\"].values\n",
    "prec_invs            = loca2_ensembles_list[            \"pr\"].values\n",
    "tmax_invs            = loca2_ensembles_list[        \"tasmax\"].values\n",
    "tmin_invs            = loca2_ensembles_list[        \"tasmin\"].values\n",
    "\n",
    "scenarios            = [\"historical\", \n",
    "                            \"ssp245\", \n",
    "                            \"ssp370\", \n",
    "                            \"ssp585\"]\n",
    "\n",
    "print(loca2_ensembles_list)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7b0ad-dc9a-4a7b-a3ab-1e42e618df93",
   "metadata": {},
   "source": [
    "## Loop for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcba28-84ee-4e83-b114-be1fcf13fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ################################################\n",
      "# ------------------------------------------------\n",
      "# ================================================\n",
      "# 001 GFDL-ESM4 r1i1p1f1 ssp245 XNP\n",
      "#  . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "    - hist_file: /data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly/historical/LOCA2-CONUS-MONTHLY_MEAN___tasmin___GFDL-ESM4.r1i1p1f1___historical.nc\n",
      "    - futr_file: /data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly/ssp245/LOCA2-CONUS-MONTHLY_MEAN___tasmin___GFDL-ESM4.r1i1p1f1___ssp245.nc\n",
      "    - comb_file: /data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly/LOCA2-CONUS-ANNUAL30YRUNMEAN_MONTHLYMEAN___tasmin___001___GFDL-ESM4.r1i1p1f1___ssp245.nc\n",
      "    - comw_file: /data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly/LOCA2-CONUS-ANNUAL30YRUNMEAN_MONTHLYMEAN___tasmin___???___*___ssp245.nc\n",
      "    - finl_file: /data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly/ssp245/LOCA2-CONUS-ANNUAL30YRUNMEAN_MONTHLYMEAN___tasmin___ALLRANK01___ssp245.nc\n",
      "#    Max_Orig_Time = 2100-12-16T12:00:00.000000000      (1032, 474, 944)\n",
      "#   Max_Merge_Time = 2100-12-16T12:00:00.000000000     (1812, 474, 944)\n",
      "Tue Dec 23 09:28:00 PM UTC 2025\n",
      "Start Reindexing 0\n",
      "Tue Dec 23 09:28:10 PM UTC 2025\n",
      "Start Rolling Mean 0\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Loop Test\n",
    "#\n",
    "\n",
    "    \n",
    "for scenario in scenarios[1:2]:\n",
    "    print(\"# ################################################\")\n",
    "    First = True\n",
    "    for m in range(len(models)-1):\n",
    "        print(\"# ------------------------------------------------\")\n",
    "\n",
    "        model          =          models[m]\n",
    "        member         =         members[m]\n",
    "        model_member   =   model_members[m]\n",
    "\n",
    "        n_complete_ens = n_complete_enss[m]\n",
    "        prec_inv       =       prec_invs[m]\n",
    "        tmax_inv       =       tmax_invs[m]\n",
    "        tmin_inv       =       tmin_invs[m]\n",
    "\n",
    "        model_member_name = np.array([model + \".\" + member], dtype=\"str\")\n",
    "        model_member      = np.array([model_member], dtype=\"int16\").flatten().astype(np.int16)\n",
    "        \n",
    "\n",
    "\n",
    "        model_member = xr.DataArray(data   = model_member.astype(np.int16),\n",
    "                                    coords = {\"model_member\":model_member.astype(np.int16)},\n",
    "                                    name   =  \"model_member\",\n",
    "                                    dims   = [\"model_member\"],\n",
    "                                    attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                              \"long_name\"   : \"Model and Member Code\",\n",
    "                                              \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                              \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "        print(\"# ================================================\")\n",
    "\n",
    "        inventory = loca2_ensembles_list.iloc[m].loc[scenario]\n",
    "        print(\"# \" + str(model_member[0].values).zfill(3) + \" \" + model + \" \" + member + \" \" + scenario + \" \" + inventory)\n",
    "\n",
    "        if (inventory != \"---\"):\n",
    "\n",
    "\n",
    "            if (\"N\" in inventory):\n",
    "\n",
    "\n",
    "\n",
    "                print(\"#  . . . . . . . . . . . . . . . . . . . . . . . .\")\n",
    "\n",
    "                hist_file         = root_directory                            +  \"/\"  + \\\n",
    "                                    \"historical\"                              +  \"/\"  + \\\n",
    "                                    Original_File_Prefix                      + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    \"historical\"                              + \".nc\"  \n",
    "\n",
    "                futr_file         = root_directory                            +  \"/\"  + \\\n",
    "                                    scenario                                  +  \"/\"  + \\\n",
    "                                    Original_File_Prefix                      + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    "\n",
    "                combined_file     = root_directory                            +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    str(model_member[0].values).zfill(3)      + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    " \n",
    "                combined_wc_files = root_directory                            +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"???\"                                     + \"___\" + \\\n",
    "                                    \"*\"                                       + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "\n",
    "                final_merged_file = root_directory                            +  \"/\"  + \\\n",
    "                                    scenario                                  +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"ALLRANK\"+ rank00                         + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "\n",
    "\n",
    "                print(\"    - hist_file: \" + hist_file)\n",
    "                print(\"    - futr_file: \" + futr_file)\n",
    "                print(\"    - comb_file: \" + combined_file)\n",
    "                print(\"    - comw_file: \" + combined_wc_files)\n",
    "                print(\"    - finl_file: \" + final_merged_file)\n",
    "                \n",
    "        \n",
    "                ds            = xr.open_dataset(filename_or_obj = futr_file)\n",
    "                time_futr_max = ds[\"time\"].values.max()\n",
    "                time_futr_n   = ds[variable].values.shape\n",
    "                \n",
    "                print(\"#    Max_Orig_Time = \" + str(time_futr_max) + \"      \" + str(time_futr_n) )\n",
    "                \n",
    "                if (First):\n",
    "                    model_member_array = np.array(model_members[m], dtype = \"int16\")\n",
    "                    First              = False\n",
    "                else:\n",
    "                    model_member_array = np.append(model_member_array, model_members[m]).flatten().astype(np.int16)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                cdo_cat_command = \"cdo --no_history -f nc4 -z zip_9  mergetime \"\n",
    "\n",
    "                command_aggregate = cdo_cat_command + hist_file + \" \" + futr_file + \" \" + tempfile\n",
    "                subprocess.run([\"rm -fr \" + tempfile],                             shell = True, check = True)\n",
    "                subprocess.run([command_aggregate],                                shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,time,d,,     \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lon,d,,      \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lat,d,,      \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lon,d,,  \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lat,d,,  \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,time,d,, \" + tempfile], shell = True, check = True)\n",
    " \n",
    "                ds              = xr.open_dataset(filename_or_obj = tempfile)\n",
    "                tasmin0         = ds[variable]\n",
    "        \n",
    "                time_merged_max = ds[\"time\"].values.max()\n",
    "                time_merged_n   = ds[variable].values.shape\n",
    "                \n",
    "                print(\"#   Max_Merge_Time = \" + str(time_merged_max) + \"     \" + str(time_merged_n) )      \n",
    "        \n",
    "                subprocess.run([\"rm -fr \" + tempfile], shell = True, check = True)\n",
    "            \n",
    "            \n",
    "                \n",
    "                time = ds[\"time\"]\n",
    "                lon = ds[\"lon\"]\n",
    "                lat = ds[\"lat\"]\n",
    "                nt = time.shape[0]\n",
    "                nm = 12\n",
    "                ny = nt/12\n",
    "\n",
    "\n",
    "                start_year = time.dt.year.min().values\n",
    "                end_year   = time.dt.year.max().values\n",
    "                year  = np.arange(start = start_year,\n",
    "                                  stop  = end_year+1,\n",
    "                                  dtype = np.int16)\n",
    "                month = np.arange(start = 1,\n",
    "                                  stop  = 12+1,\n",
    "                                  dtype = np.int16)\n",
    "                \n",
    "                yeardv = xr.DataArray(data   =  year,\n",
    "                                    dims   = \"year\",\n",
    "                                    coords = {\"year\": year},\n",
    "                                    attrs  = {\"description\": \"calendar year\",\n",
    "                                                \"long_name\": \"calendar year\"})\n",
    "                \n",
    "                monthdv = xr.DataArray(data   =  month,\n",
    "                                      dims    = \"month\",\n",
    "                                      coords  = {\"month\": month},\n",
    "                                      attrs   = {\"description\": \"calendar month\",\n",
    "                                                   \"long_name\": \"calendar month\"})\n",
    "                \n",
    "                print(\"Start Reindexing\",os.system(\"date\"))\n",
    "                \n",
    "                multiindex_ds = ds.assign_coords(month = monthdv,\n",
    "                                                 year  = yeardv).  \\\n",
    "                                   stack(time2d=(\"year\",\n",
    "                                                 \"month\")).        \\\n",
    "                                   reset_index(\"time\", drop=True). \\\n",
    "                                   rename(time=\"time2d\").          \\\n",
    "                                   unstack(\"time2d\")\n",
    "\n",
    "                print(\"Start Rolling Mean\",os.system(\"date\"))\n",
    "\n",
    "                \n",
    "                rolling_monthly = multiindex_ds[variable].rolling(year   =   30,\n",
    "                                                                  center = True).mean().dropna(dim = \"year\",\n",
    "                                                                                               how =  \"all\") \n",
    "                rolling_monthly.expand_dims(dim={\"model_member\" : 1}) \n",
    "                rolling_monthly.attrs[\"cell_methods\"] = cell_method\n",
    "                #del rolling_monthly.attrs[\"coordinates\"]\n",
    "                print(rolling_monthly[\"time\"].values)\n",
    "                print(\"Finished Rolling Mean\",os.system(\"date\"))\n",
    "\n",
    "\n",
    "                outdata = xr.Dataset(data_vars = {variable       :               rolling_monthly,\n",
    "                                                  \"lat\"          :                           lat,\n",
    "                                                  \"lon\"          :                           lon,\n",
    "                                                  \"model_member\" : model_member.astype(np.int16)},\n",
    "                                     attrs     = {\"scenario\"     :                      scenario})\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                outdata.to_netcdf(path           =  combined_file, \n",
    "                                  mode           =            'w', \n",
    "                                  format         =      \"NETCDF4\",\n",
    "                                  engine         =     \"h5netcdf\", #\n",
    "                                  unlimited_dims = \"model_member\",\n",
    "                                  encoding       = {variable: {        \"dtype\": \"int16\", \n",
    "                                                                \"scale_factor\":     0.1,\n",
    "                                                                  \"add_offset\":     0.0,                                        \n",
    "                                                                  \"_FillValue\":  -32767}})\n",
    "\n",
    "                print(\"Writing NetCDF Climate File\",os.system(\"date\"))\n",
    "                \n",
    "                subprocess.run([local_hdf_string+\" ncatted -Oh -a _FillValue,lon,d,, \" + combined_file], \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "                subprocess.run([local_hdf_string+\" ncatted  -Oh -a _FillValue,lat,d,, \" + combined_file], \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "\n",
    "                subprocess.run([local_hdf_string + \" ncpdq  -h -a year,month,lat,lon \" + combined_file + \" \" + combined_file+\".swapped.nc\"],\n",
    "                                shell = True, \n",
    "                                check = True)      \n",
    "                print(\"Correcting all Dimensions\",os.system(\"date\"))\n",
    "\n",
    "                subprocess.run([\"mv -v \" + combined_file + \".swapped.nc \" + combined_file],\n",
    "                                shell = True,  \n",
    "                                check = True)                               \n",
    "                ds               = xr.open_dataset(filename_or_obj = combined_file)\n",
    "                time_running_max = ds[\"year\"].values.max()\n",
    "                time_running_n   = ds[variable].values.shape\n",
    "                print(\"# Max_Running_Time = \" + str(time_running_max) + \"  \" + str(time_running_n) )                                 \n",
    "                \n",
    "            # end check on available variable\n",
    "        # end check on on available member\n",
    "            \n",
    "    #end loop on model\n",
    "\n",
    "    print(\"# = = = = = = = = = = = = = = = = = = = = = = = = \") \n",
    "    \n",
    "    model_member = xr.DataArray(data   = model_member_array.astype(np.int16),\n",
    "                                name   =  \"model_member\",\n",
    "                                dims   = [\"model_member\"],\n",
    "                                attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                          \"long_name\"   : \"Model and Member Code\",\n",
    "                                          \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                          \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "    model_member_ds = xr.Dataset(data_vars = {\"model_member\" : model_member})\n",
    "    \n",
    "    model_member_ds.to_netcdf(path            =   memberfile, \n",
    "                               mode           =           'w', \n",
    "                               format         =     \"NETCDF4\",\n",
    "                               engine         =    \"h5netcdf\", #\n",
    "                               unlimited_dims = \"model_member\")  \n",
    "        \n",
    "    cdo_cat_command = \" cdo --no_history -f nc4 -z zip_9 cat \"\n",
    "    nco_cat_command = \" ncrcat --4 --hst --dfl_lvl 9  \"\n",
    "    command_aggregate = nco_cat_command +combined_wc_files + \" \" + final_merged_file    \n",
    "    print(\"# Final Aggregation\")\n",
    "    subprocess.run([\"rm -fr \" + final_merged_file + \" \" + tempfile + \" 2_\" + tempfile], \n",
    "                   shell = True, \n",
    "                   check = True)    \n",
    "    subprocess.run([local_hdf_string + command_aggregate], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# Files Concatenated\")\n",
    "\n",
    "    #subprocess.run([local_hdf_string+\" ncks -h -C -O -x -v model_member \" + tempfile + \" \" + final_merged_file], \n",
    "    #               shell = True, \n",
    "    #               check = True)\n",
    "    #print(\"# dimension dropped\")\n",
    "    #subprocess.run([local_hdf_string+\" ncks -h -A \"+ memberfile + \" \" + final_merged_file], \n",
    "    #               shell = True, \n",
    "    #               check = True)\n",
    "    ds               = xr.open_dataset(filename_or_obj = final_merged_file)\n",
    "    time_running_max = ds[\"year\"].values.max()\n",
    "    time_running_n   = ds[variable].values.shape\n",
    "    print(\"#     Max_Ens_Time = \" + str(time_running_max) + \" \" + str(time_running_n) )  \n",
    "    print(\"# dimension swapped\")\n",
    "    subprocess.run([\"rm -fr  \" + tempfile + \" 2_\" + tempfile + \" \" + combined_wc_files], \n",
    "                   shell = True, \n",
    "                   check = True) \n",
    "\n",
    "# end loop on scenario\n",
    "                \n",
    "print(\"# ================================================\")\n",
    "print(\"end processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5237d-f41d-45e5-8507-9b6ce3af1107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094c6cd9-732c-4dd0-a889-5ab5e1004edc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9fa46-4b84-4a54-bfd7-417b132bd4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
