{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a671d21-2480-4b9b-9be1-c31f94ee912a",
   "metadata": {},
   "source": [
    "# LOCA2 30-year Moving Mean Monthly Max Temps Future Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf373a4-9794-4ddf-a5aa-aafc395e58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Library Calls.\n",
    "#\n",
    "\n",
    "# loading numpy\n",
    "\n",
    "import numpy             as np\n",
    "\n",
    "# loading matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading xarray\n",
    "\n",
    "import xarray            as xr\n",
    "\n",
    "import datetime as datetime\n",
    "\n",
    "# Loading pandas\n",
    "\n",
    "import pandas            as pd\n",
    "\n",
    "import os as os\n",
    "\n",
    "import subprocess as subprocess\n",
    "\n",
    "def geo_idx(dd, dd_array):\n",
    "\n",
    "    geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "    return geo_idx\n",
    " \n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad579283-7a18-48d0-ae9f-68d6444a0b3e",
   "metadata": {},
   "source": [
    "##  File Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993baf1-e898-4c48-8b10-e10dd4ec1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# File Control\n",
    "#\n",
    "\n",
    "Original_File_Prefix = \"LOCA2-CONUS-MONTHLY_MEAN\"\n",
    "Final_File_Prefix    = \"LOCA2-CONUS-ANNUAL30YRUNMEAN_MONTHLYMEAN\"\n",
    "\n",
    "variable    = \"tasmax\"\n",
    "\n",
    "tempfile    = \"./\" + variable + \"_tempfile.nc\"\n",
    "memberfile  = \"./\" + variable + \"_model_member.nc\"\n",
    "\n",
    "local_hdf_string = \"export HDF5_USE_FILE_LOCKING=FALSE && \"\n",
    "local_hdf_string = \" \"\n",
    "\n",
    "cell_method    = \"time: maximum within days  time: mean within months  time: mean over 30 years \"\n",
    "\n",
    "target_rank =  \"1\"\n",
    "rank00      = \"01\"\n",
    "\n",
    "root_directory        = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly\"\n",
    "root_url              = \"http://kyrill.ias.sdsmt.edu:8080/thredds/dodsC/LOCA2/Climate_CONUS/Monthly\"\n",
    "\n",
    "loca2_inventory_file  = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/LOCA2_Model_Member_Available_List.csv\"\n",
    "loca2_complete_file   = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/LOCA2_Model_Member_Complete_List.csv\"\n",
    "\n",
    "loca2_mask            = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/LOCA2_MASKS.nc\"\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f970dc89-b432-427f-bf42-24162c298f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Time Coordinates\n",
    "#\n",
    "\n",
    "years_start = np.arange(start =    1986, \n",
    "                        stop  =    2071,   dtype=np.float32)\n",
    "years_end   = np.array(years_start + 29, dtype=np.float32) \n",
    "\n",
    "years_middle = np.array(years_start/2 + years_end/2, dtype=np.float32)\n",
    "years_bounds = np.array([years_start,years_end]).transpose()\n",
    "n_runnings = len(years_start)\n",
    "\n",
    "yearall = xr.DataArray(name = \"year\",\n",
    "                      data   = years_middle,\n",
    "                      dims   = {\"year\": n_runnings},\n",
    "                      coords = {\"year\": years_middle},\n",
    "                      attrs  = {\"description\": \"middle calendar year for 30-yr period\",\n",
    "                                \"long_name\": \"middle calendar year for 30-yr period\",\n",
    "                                \"bounds\":\"year_bnds\"})\n",
    "\n",
    "\n",
    "year_bnds = xr.DataArray(name = \"year_bnds\",\n",
    "                      data   =  years_bounds,\n",
    "                      coords = {\"year\": years_middle,\n",
    "                                \"bnds\": 2},\n",
    "                      attrs  = {\"description\": \"boundary calendar years for 30-yr period\",\n",
    "                                \"long_name\": \"boundary calendar years for 30-yr period\"})\n",
    "\n",
    "\n",
    "ds_masks = xr.open_dataset(filename_or_obj = loca2_mask)\n",
    "\n",
    "lon_bnds = ds_masks[\"lon_bounds\"]\n",
    "lat_bnds = ds_masks[\"lat_bounds\"]\n",
    "lat_bnds.name = \"lat_bnds\"\n",
    "lon_bnds.name = \"lon_bnds\"\n",
    "\n",
    "lon = ds_masks[\"lon\"]\n",
    "lat = ds_masks[\"lat\"]\n",
    "\n",
    "\n",
    "print(lat)\n",
    "print(lon)\n",
    "print(year_bnds)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a0503-94b1-4c5a-a0fe-c98ccbb56990",
   "metadata": {},
   "source": [
    "## Inventories and Lookup Tables\n",
    "### All Potential Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55407694-92d9-401f-9327-749aa795de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Inventory and Model/Member Lookup Table for all Possible Ensembles\n",
    "#\n",
    "\n",
    "\n",
    "loca2_complete_list = pd.read_csv(filepath_or_buffer = loca2_complete_file)\n",
    "\n",
    "modelsc               = loca2_complete_list[         \"Model\"].values\n",
    "membersc              = loca2_complete_list[        \"Member\"].values\n",
    "model_membersc        = loca2_complete_list[  \"Model_Member\"].values\n",
    "\n",
    "model_member_key0 = np.array(modelsc+\".\"+membersc, dtype=\"str\")\n",
    "model_member_key =  np.array([\"NULL\"], dtype=\"str\")\n",
    "\n",
    "model_members_to_save = np.append(0,model_membersc)\n",
    "\n",
    "model_member_key = np.append(model_member_key,model_member_key0)\n",
    "\n",
    "\n",
    "model_member_key    = xr.DataArray(model_member_key, \n",
    "                                   coords={\"model_member\":model_members_to_save},\n",
    "                                   name  = \"model_member_key\",\n",
    "                                   dims  = [\"model_member\"],\n",
    "                                   attrs = {\"description\" : \"Model and Member Label\",\n",
    "                                              \"long_name\" : \"Model and Member Label\",\n",
    "                                               \"comment1\" :   \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "print(model_member_key)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ffdc9-92ac-4e18-bc58-c870a0f50b84",
   "metadata": {},
   "source": [
    "### All Available Ensembles for Selected Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046bd9b-7af6-45e6-a7bb-b4cfc3597444",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Inventory and Model/Member Lookup Table for all Possible Ensembles\n",
    "#\n",
    "\n",
    "loca2_ensembles_list = pd.read_csv(filepath_or_buffer = loca2_inventory_file)\n",
    "\n",
    "loca2_ensembles_list = loca2_ensembles_list.query(\"Rank == \" + target_rank)\n",
    "\n",
    "models               = loca2_ensembles_list[         \"Model\"].values\n",
    "members              = loca2_ensembles_list[        \"Member\"].values\n",
    "model_members        = loca2_ensembles_list[  \"Model_Member\"].values\n",
    "n_complete_enss      = loca2_ensembles_list[\"n_complete_ens\"].values\n",
    "historical_invs      = loca2_ensembles_list[    \"historical\"].values\n",
    "ssp245_invs          = loca2_ensembles_list[        \"ssp245\"].values\n",
    "ssp370_invs          = loca2_ensembles_list[        \"ssp370\"].values\n",
    "ssp585_invs          = loca2_ensembles_list[        \"ssp585\"].values\n",
    "prec_invs            = loca2_ensembles_list[            \"pr\"].values\n",
    "tmax_invs            = loca2_ensembles_list[        \"tasmax\"].values\n",
    "tmin_invs            = loca2_ensembles_list[        \"tasmin\"].values\n",
    "\n",
    "scenarios            = [\"historical\", \n",
    "                            \"ssp245\", \n",
    "                            \"ssp370\", \n",
    "                            \"ssp585\"]\n",
    "\n",
    "print(loca2_ensembles_list)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7b0ad-dc9a-4a7b-a3ab-1e42e618df93",
   "metadata": {},
   "source": [
    "## Loop for Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcba28-84ee-4e83-b114-be1fcf13fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Loop Test\n",
    "#\n",
    "\n",
    "    \n",
    "for scenario in scenarios[1:]:\n",
    "    print(\"# ################################################\")\n",
    "    print(\"# ################################################\")\n",
    "    print(\"# ################################################\")\n",
    "    First = True\n",
    "    for m in range(len(models)-1):\n",
    "        print(\"# ------------------------------------------------\")\n",
    "\n",
    "        model          =          models[m]\n",
    "        member         =         members[m]\n",
    "        model_member   =   model_members[m]\n",
    "\n",
    "        n_complete_ens = n_complete_enss[m]\n",
    "        prec_inv       =       prec_invs[m]\n",
    "        tmax_inv       =       tmax_invs[m]\n",
    "        tmin_inv       =       tmin_invs[m]\n",
    "\n",
    "        model_member_name = np.array([model + \".\" + member], dtype=\"str\")\n",
    "        model_member      = np.array([model_member], dtype=\"int16\").flatten().astype(np.int16)\n",
    "        \n",
    "\n",
    "\n",
    "        model_member = xr.DataArray(data   = model_member.astype(np.int16),\n",
    "                                    coords = {\"model_member\":model_member.astype(np.int16)},\n",
    "                                    name   =  \"model_member\",\n",
    "                                    dims   = [\"model_member\"],\n",
    "                                    attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                              \"long_name\"   : \"Model and Member Code\",\n",
    "                                              \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                              \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "        print(\"# ================================================\")\n",
    "\n",
    "        inventory = loca2_ensembles_list.iloc[m].loc[scenario]\n",
    "        print(\"# \" + str(model_member[0].values).zfill(3) + \" \" + model + \" \" + member + \" \" + scenario + \" \" + inventory)\n",
    "\n",
    "        if (inventory != \"---\"):\n",
    "\n",
    "\n",
    "            if (\"X\" in inventory):\n",
    "\n",
    "\n",
    "\n",
    "                print(\"#  . . . . . . . . . . . . . . . . . . . . . . . .\")\n",
    "\n",
    "                hist_file         = root_directory                            +  \"/\"  + \\\n",
    "                                    \"historical\"                              +  \"/\"  + \\\n",
    "                                    Original_File_Prefix                      + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    \"historical\"                              + \".nc\"  \n",
    "\n",
    "                futr_file         = root_directory                            +  \"/\"  + \\\n",
    "                                    scenario                                  +  \"/\"  + \\\n",
    "                                    Original_File_Prefix                      + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    "\n",
    "                combined_file     = root_directory                            +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    str(model_member[0].values).zfill(3)      + \"___\" + \\\n",
    "                                    models[m]                                 +  \".\"  + \\\n",
    "                                    members[m]                                + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    " \n",
    "                combined_wc_files = root_directory                            +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"???\"                                     + \"___\" + \\\n",
    "                                    \"*\"                                       + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "\n",
    "                final_merged_file = root_directory                            +  \"/\"  + \\\n",
    "                                    scenario                                  +  \"/\"  + \\\n",
    "                                    Final_File_Prefix                         + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"ALLRANK\"+ rank00                         + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "\n",
    "\n",
    "                print(\"    - hist_file: \" + hist_file)\n",
    "                print(\"    - futr_file: \" + futr_file)\n",
    "                print(\"    - comb_file: \" + combined_file)\n",
    "                print(\"    - comw_file: \" + combined_wc_files)\n",
    "                print(\"    - finl_file: \" + final_merged_file)\n",
    "                \n",
    "        \n",
    "                ds            = xr.open_dataset(filename_or_obj = futr_file)\n",
    "                time_futr_max = ds[\"time\"].values.max()\n",
    "                time_futr_n   = ds[variable].values.shape\n",
    "                \n",
    "                print(\"#    Max_Orig_Time = \" + str(time_futr_max) + \"      \" + str(time_futr_n) )\n",
    "                \n",
    "                if (First):\n",
    "                    model_member_array = np.array(model_members[m], dtype = \"int16\")\n",
    "                    First              = False\n",
    "                else:\n",
    "                    model_member_array = np.append(model_member_array, model_members[m]).flatten().astype(np.int16)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                cdo_cat_command = \"cdo --no_history -f nc4 -z zip_9  mergetime \"\n",
    "\n",
    "                command_aggregate = cdo_cat_command + hist_file + \" \" + futr_file + \" \" + tempfile\n",
    "                subprocess.run([\"rm -fr \" + tempfile],                             shell = True, check = True)\n",
    "                subprocess.run([command_aggregate],                                shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lon,d,,      \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lat,d,,      \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lon,d,,  \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lat,d,,  \" + tempfile], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,time,d,, \" + tempfile], shell = True, check = True)\n",
    " \n",
    "                ds              = xr.open_dataset(filename_or_obj = tempfile)\n",
    "                tasmin0         = ds[variable]\n",
    "        \n",
    "                time_merged_max = ds[\"time\"].values.max()\n",
    "                time_merged_n   = ds[variable].values.shape\n",
    "                \n",
    "                print(\"#   Max_Merge_Time = \" + str(time_merged_max) + \"     \" + str(time_merged_n) )      \n",
    "        \n",
    "                subprocess.run([\"rm -fr \" + tempfile], shell = True, check = True)\n",
    "            \n",
    "            \n",
    "                \n",
    "                time = ds[\"time\"]\n",
    "                lon = ds[\"lon\"]\n",
    "                lat = ds[\"lat\"]\n",
    "                nt = time.shape[0]\n",
    "                nm = 12\n",
    "                ny = nt/12\n",
    "\n",
    "\n",
    "                start_year = time.dt.year.min().values\n",
    "                end_year   = time.dt.year.max().values\n",
    "                year  = np.arange(start = start_year,\n",
    "                                  stop  = end_year+1,\n",
    "                                  dtype = np.int16)\n",
    "                month = np.arange(start = 1,\n",
    "                                  stop  = 12+1,\n",
    "                                  dtype = np.int16)\n",
    "                \n",
    "                yeardv = xr.DataArray(name = \"year\",\n",
    "                                      data   =  year,\n",
    "                                    dims   = \"year\",\n",
    "                                    coords = {\"year\": year},\n",
    "                                    attrs  = {\"description\": \"beginning period calendar year\",\n",
    "                                                \"long_name\": \"beginning period calendar year\"})\n",
    "\n",
    "\n",
    "                \n",
    "                monthdv = xr.DataArray(data   =  month,\n",
    "                                      dims    = \"month\",\n",
    "                                      coords  = {\"month\": month},\n",
    "                                      attrs   = {\"description\": \"calendar month\",\n",
    "                                                   \"long_name\": \"calendar month\"})\n",
    "                \n",
    "                print(\"Start Reindexing\",os.system(\"date\"))\n",
    "                \n",
    "                multiindex_ds = ds.assign_coords(month = monthdv,\n",
    "                                                 year  = yeardv).  \\\n",
    "                                   stack(time2d=(\"year\",\n",
    "                                                 \"month\")).        \\\n",
    "                                   reset_index(\"time\", drop=True). \\\n",
    "                                   rename(time=\"time2d\").          \\\n",
    "                                   unstack(\"time2d\").drop_vars(\"time_bnds\")\n",
    "\n",
    "                print(\"Start Rolling Mean\",os.system(\"date\"))\n",
    "\n",
    "                \n",
    "                for i in range(n_runnings):\n",
    "                    if ((i % 10) == 0):\n",
    "                        print(\"   --- Processing \",years_start[i] , \"to\", years_end[i])\n",
    "                \n",
    "                    year_co = xr.DataArray(name = \"year\",\n",
    "                                           data   =np.array([years_start[i]/2+years_end[i]/2], dtype=np.float32),\n",
    "                                           dims   = \"year\",\n",
    "                                           coords = {\"year\": np.array([years_start[i]], dtype=np.int16)},\n",
    "                                           attrs  = {\"description\": \"beginning period calendar year\",\n",
    "                                                     \"long_name\": \"beginning period calendar year\"})\n",
    "                    \n",
    "                    if (i == 0):\n",
    "                        running_var = multiindex_ds[variable].sel(year = slice(years_start[i],years_end[i])).mean(dim=\"year\", keep_attrs = True).transpose(\"month\",\"lat\",\"lon\").expand_dims(dim={\"model_member\" : 1,\"year\":1}) \n",
    "                        running_var.coords[\"model_member\"]=model_member\n",
    "                        running_var.coords[\"year\"] = year_co\n",
    "                    else:\n",
    "                        temp_30 = multiindex_ds[variable].sel(year = slice(years_start[i],years_end[i])).mean(dim=\"year\").transpose(\"month\",\"lat\",\"lon\").expand_dims(dim={\"model_member\" : 1,\"year\":1}) \n",
    "                        temp_30.coords[\"model_member\"]=model_member\n",
    "                        temp_30.coords[\"year\"] = year_co\n",
    "                        running_var = xr.concat([running_var, temp_30], dim = \"year\")\n",
    "                        del temp_30\n",
    "                        \n",
    "                print(\"Finished Rolling Mean\",os.system(\"date\"))\n",
    "\n",
    "                running_var.attrs[\"cell_methods\"] = cell_method\n",
    "\n",
    "                outdata = xr.Dataset(data_vars = {\"model_member\" : model_member.astype(np.int16),\n",
    "                                                  \"year\"         : yearall,\n",
    "                                                #  \"year_bnds\"    : year_bnds,\n",
    "                                                  \"month\"        : monthdv,\n",
    "                                                  \"lat\"          : lat,\n",
    "                                                  #\"lat_bnds\"     : lat_bnds,\n",
    "                                                  \"lon\"          : lon,\n",
    "                                                  #\"lon_bnds\"     : lon_bnds,\n",
    "                                                   variable      : running_var},\n",
    "                                     attrs     = {\"scenario\"     : scenario})\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                outdata.to_netcdf(path           =  combined_file, \n",
    "                                  mode           =            'w', \n",
    "                                  format         =      \"NETCDF4\",\n",
    "                                  engine         =     \"h5netcdf\", #\n",
    "                                  unlimited_dims = \"model_member\",\n",
    "                                  encoding       = {variable: {         \"zlib\":    True,\n",
    "                                                                  \"complevel\" :       7, \n",
    "                                                                       \"dtype\": \"int16\", \n",
    "                                                                \"scale_factor\":     0.1,\n",
    "                                                                  \"add_offset\":     0.0,                                        \n",
    "                                                                  \"_FillValue\":  -32767}})\n",
    "\n",
    "                print(\"Writing NetCDF Climate File\",os.system(\"date\"))\n",
    "                \n",
    "\n",
    "                             \n",
    "                \n",
    "            # end check on available variable\n",
    "        # end check on on available member\n",
    "            \n",
    "    #end loop on model\n",
    "\n",
    "    print(\"# = = = = = = = = = = = = = = = = = = = = = = = = \") \n",
    "    \n",
    "    model_member = xr.DataArray(data   = model_member_array.astype(np.int16),\n",
    "                                name   =  \"model_member\",\n",
    "                                dims   = [\"model_member\"],\n",
    "                                attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                          \"long_name\"   : \"Model and Member Code\",\n",
    "                                          \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                          \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "    model_member_ds = xr.Dataset(data_vars = {\"model_member\" : model_member})\n",
    "    \n",
    "    model_member_ds.to_netcdf(path            =   memberfile, \n",
    "                               mode           =           'w', \n",
    "                               format         =     \"NETCDF4\",\n",
    "                               engine         =    \"h5netcdf\", #\n",
    "                               unlimited_dims = \"model_member\")  \n",
    "        \n",
    "    cdo_cat_command = \" cdo --no_history -f nc4 -z zip_9 cat \"\n",
    "    nco_cat_command = \" ncrcat --4 --hst --dfl_lvl 9  \"\n",
    "    command_aggregate = nco_cat_command +combined_wc_files + \" \" + final_merged_file    \n",
    "    print(\"# Final Aggregation for \"+scenario)\n",
    "    subprocess.run([\"rm -fr \" + final_merged_file + \" \" + tempfile + \" 2_\" + tempfile], \n",
    "                   shell = True, \n",
    "                   check = True)    \n",
    "    subprocess.run([local_hdf_string + command_aggregate], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# Files Concatenated\")\n",
    "    subprocess.run([\"rm -frv \" + combined_wc_files], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# Files Cleaned\")\n",
    "\n",
    "\n",
    "# end loop on scenario\n",
    "                \n",
    "print(\"# ================================================\")\n",
    "print(\"end processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a897ee-2980-4f3c-ba78-06774e4bf0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ff726-a1e5-40ad-9fe8-8053c821870e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747699fa-7f99-4db5-8b73-3c25f1efd84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
