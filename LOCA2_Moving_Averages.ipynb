{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a671d21-2480-4b9b-9be1-c31f94ee912a",
   "metadata": {},
   "source": [
    "# LOCA2 Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf373a4-9794-4ddf-a5aa-aafc395e58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Library Calls.\n",
    "#\n",
    "\n",
    "# loading numpy\n",
    "\n",
    "import numpy             as np\n",
    "\n",
    "# loading matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading xarray\n",
    "\n",
    "import xarray            as xr\n",
    "\n",
    "# Loading pandas\n",
    "\n",
    "import pandas            as pd\n",
    "\n",
    "\n",
    "\n",
    "import subprocess as subprocess\n",
    "\n",
    "\n",
    "\n",
    "def geo_idx(dd, dd_array):\n",
    "   \"\"\"\n",
    "     search for nearest decimal degree in an array of decimal degrees and return the index.\n",
    "     np.argmin returns the indices of minium value along an axis.\n",
    "     so subtract dd from all values in dd_array, take absolute value and find index of minium.\n",
    "    \"\"\"\n",
    "   geo_idx = (np.abs(dd_array - dd)).argmin()\n",
    "   return geo_idx\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad579283-7a18-48d0-ae9f-68d6444a0b3e",
   "metadata": {},
   "source": [
    "##  Inventory and Model/Member Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993baf1-e898-4c48-8b10-e10dd4ec1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Inventory and Model/Member Lookup Table\n",
    "#\n",
    "\n",
    "root_directory       = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly/\"\n",
    "root_url             = \"http://kyrill.ias.sdsmt.edu:8080/thredds/dodsC/LOCA2/Climate_CONUS/Monthly/\"\n",
    "\n",
    "loca2_complete_file  = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Original_CONUS/LOCA2_Model_Member_Complete_List.csv\"\n",
    "\n",
    "loca2_complete_list = pd.read_csv(filepath_or_buffer = loca2_complete_file)\n",
    "\n",
    "\n",
    "modelsc               = loca2_complete_list[         \"Model\"].values\n",
    "membersc              = loca2_complete_list[        \"Member\"].values\n",
    "model_membersc        = loca2_complete_list[  \"Model_Member\"].values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_member_key0 = np.array(modelsc+\".\"+membersc, dtype=\"str\")\n",
    "model_member_key =  np.array([\"NULL\"], dtype=\"str\")\n",
    "\n",
    "model_members_to_save = np.append(0,model_membersc)\n",
    "\n",
    "model_member_key = np.append(model_member_key,model_member_key0)\n",
    "\n",
    "\n",
    "model_member_key    = xr.DataArray(model_member_key, \n",
    "                                   coords={\"model_member\":model_members_to_save},\n",
    "                                   name  = \"model_member_key\",\n",
    "                                   dims  = [\"model_member\"],\n",
    "                                   attrs = {\"description\" : \"Model and Member Label\",\n",
    "                                              \"long_name\" : \"Model and Member Label\",\n",
    "                                               \"comment1\" :   \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "\n",
    "\n",
    "display(model_member_key)\n",
    "\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ffdc9-92ac-4e18-bc58-c870a0f50b84",
   "metadata": {},
   "source": [
    "## File and Inventory Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046bd9b-7af6-45e6-a7bb-b4cfc3597444",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# File and Inventory Control\n",
    "#\n",
    "\n",
    "root_directory       = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Monthly/\"\n",
    "root_url             = \"http://kyrill.ias.sdsmt.edu:8080/thredds/dodsC/LOCA2/Climate_CONUS/Monthly/\"\n",
    "\n",
    "loca2_inventory_file = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Original_CONUS/LOCA2_Model_Member_Available_List.csv\"\n",
    "\n",
    "loca2_ensembles_list = pd.read_csv(filepath_or_buffer = loca2_inventory_file)\n",
    "\n",
    "loca2_ensembles_list = loca2_ensembles_list.query('Rank == 1')\n",
    "\n",
    "models               = loca2_ensembles_list[         \"Model\"].values\n",
    "members              = loca2_ensembles_list[        \"Member\"].values\n",
    "model_members        = loca2_ensembles_list[  \"Model_Member\"].values\n",
    "ranks                = loca2_ensembles_list[          \"Rank\"].values\n",
    "n_complete_enss      = loca2_ensembles_list[\"n_complete_ens\"].values\n",
    "historical_invs      = loca2_ensembles_list[    \"historical\"].values\n",
    "ssp245_invs          = loca2_ensembles_list[        \"ssp245\"].values\n",
    "ssp370_invs          = loca2_ensembles_list[        \"ssp370\"].values\n",
    "ssp585_invs          = loca2_ensembles_list[        \"ssp585\"].values\n",
    "\n",
    "prec_invs = loca2_ensembles_list[    \"pr\"].values\n",
    "tmax_invs = loca2_ensembles_list[\"tasmax\"].values\n",
    "tmin_invs = loca2_ensembles_list[\"tasmin\"].values\n",
    "\n",
    "scenarios            = [\"historical\", \n",
    "                            \"ssp245\", \n",
    "                            \"ssp370\", \n",
    "                            \"ssp585\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(loca2_ensembles_list)\n",
    "\n",
    "#\n",
    "##########################################################\n",
    "\n",
    "\n",
    "rank = str(ranks[3]).zfill(2)\n",
    "display(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a1b2f-823e-4846-89ff-e635c178f295",
   "metadata": {},
   "source": [
    "# Pull Geospatial Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba89529-0e80-4db7-8876-4bb1e2d3065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(rank)\n",
    "#\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7b0ad-dc9a-4a7b-a3ab-1e42e618df93",
   "metadata": {},
   "source": [
    "## Loop for Resultsmodel_member_key.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcba28-84ee-4e83-b114-be1fcf13fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Loop Test\n",
    "#\n",
    "\n",
    "root_directory_A       = \"/data/DATASETS/LOCA_MACA_Ensembles/LOCA2/LOCA2_CONUS/Climate_CONUS/Annual\"\n",
    "    \n",
    "for scenario in scenarios[1:]:\n",
    "    print(\"# ################################################\")\n",
    "    First = True\n",
    "    for m in range(len(models)-1):\n",
    "        print(\"# ------------------------------------------------\")\n",
    "\n",
    "        model          =          models[m]\n",
    "        member         =         members[m]\n",
    "        model_member   =   model_members[m]\n",
    "        rank           =   str(ranks[m]).zfill(2)\n",
    "\n",
    "        n_complete_ens = n_complete_enss[m]\n",
    "        prec_inv       =       prec_invs[m]\n",
    "        tmax_inv       =       tmax_invs[m]\n",
    "        tmin_inv       =       tmin_invs[m]\n",
    "\n",
    "        model_member_name = np.array([model + \".\" + member], dtype=\"str\")\n",
    "        model_member      = np.array([model_member], dtype=\"int16\").flatten()\n",
    "\n",
    "        model_member = xr.DataArray(data   = model_member,\n",
    "                                    coords = {\"model_member\":model_member},\n",
    "                                    name   =  \"model_member\",\n",
    "                                    dims   = [\"model_member\"],\n",
    "                                    attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                              \"long_name\"   : \"Model and Member Code\",\n",
    "                                              \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                              \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "        file_url_h = root_directory + \"/\" + scenarios[0] + \"/LOCA2-CONUS-ANNUAL_MIN___tasmin___\" + model + \".\" + member + \"___\" + scenarios[0] + \".nc\"\n",
    "\n",
    "        print(\"# ================================================\")\n",
    "\n",
    "        inventory = loca2_ensembles_list.iloc[m].loc[scenario]\n",
    "        print(\"# \" + str(model_member[0].values).zfill(3) + \" \" + model + \" \" + member + \" \" + scenario + \" \" + inventory)\n",
    "\n",
    "        if (inventory != \"---\"):\n",
    "\n",
    "\n",
    "            if (\"N\" in inventory):\n",
    "\n",
    "                variable    = \"tasmin\"\n",
    "\n",
    "                print(\"#  . . . . . . . . . . . . . . . . . . . . . . . .\")\n",
    "\n",
    "                hist_file         = root_directory_A                          +  \"/\"  + \\\n",
    "                                    \"historical\"                              +  \"/\"  + \\\n",
    "                                    \"LOCA2-CONUS-ANNUAL_MIN\"                  + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    loca2_ensembles_list.at[m,\"Model\"]        +  \".\"  + \\\n",
    "                                    loca2_ensembles_list.at[m,\"Member\"]       + \"___\" + \\\n",
    "                                    \"historical\"                              + \".nc\"  \n",
    "\n",
    "                futr_file         = root_directory_A                          +  \"/\"  + \\\n",
    "                                    scenario                                  +  \"/\"  + \\\n",
    "                                    \"LOCA2-CONUS-ANNUAL_MIN\"                  + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    loca2_ensembles_list.at[m,\"Model\"]        +  \".\"  + \\\n",
    "                                    loca2_ensembles_list.at[m,\"Member\"]       + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    "\n",
    "                combined_file     = root_directory_A                          +  \"/\"  + \\\n",
    "                                    \"LOCA2-CONUS-ANNUAL30YRUNMEAN_MIN\"        + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    str(model_member[0].values).zfill(3)      + \"___\" + \\\n",
    "                                    loca2_ensembles_list.at[m,\"Model\"]        +  \".\"  + \\\n",
    "                                    loca2_ensembles_list.at[m,\"Member\"]       + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\"  \n",
    " \n",
    "                combined_wc_files = root_directory_A                          +  \"/\"  + \\\n",
    "                                    \"LOCA2-CONUS-ANNUAL30YRUNMEAN_MIN\"        + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"???\"                                     + \"___\" + \\\n",
    "                                    \"*\"                                       + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "\n",
    "                final_merged_file = root_directory_A                          +  \"/\"  + \\\n",
    "                                    \"LOCA2-CONUS-ANNUAL30YRUNMEAN_MIN\"        + \"___\" + \\\n",
    "                                    variable                                  + \"___\" + \\\n",
    "                                    \"ALLRANK\"+ rank                           + \"___\" + \\\n",
    "                                    scenario                                  + \".nc\" \n",
    "        \n",
    "                if (First):\n",
    "                    model_member_array = np.array(model_members[m], dtype = \"int16\")\n",
    "                    First              = False\n",
    "                else:\n",
    "                    model_member_array = np.append(model_member_array, model_members[m]).flatten()\n",
    "                    \n",
    "                    \n",
    "\n",
    "                cdo_cat_command = \"nohup cdo --no_history -f nc4 -z zip_9 cat \"\n",
    "\n",
    "                command_aggregate = cdo_cat_command + hist_file + \" \" + futr_file + \" ./deleteme.nc\"\n",
    "                subprocess.run([\"rm -fr ./deleteme.nc\"], shell = True, check = True)\n",
    "                subprocess.run([command_aggregate], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,time,d,, ./deleteme.nc\"], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lon,d,, ./deleteme.nc\"], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a bounds,lat,d,, ./deleteme.nc\"], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lon,d,, ./deleteme.nc\"], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,lat,d,, ./deleteme.nc\"], shell = True, check = True)\n",
    "                subprocess.run([\"ncatted -Oh -a _FillValue,time,d,, ./deleteme.nc\"], shell = True, check = True)\n",
    "                xf_h = xr.open_dataset(filename_or_obj = \"./deleteme.nc\")\n",
    "                tasmin0 = xf_h[\"tasmin\"]\n",
    "                subprocess.run([\"rm -fr ./deleteme.nc\"], shell = True, check = True)\n",
    "\n",
    "\n",
    "\n",
    "                tasmin = tasmin0.rolling(time   =   30, \n",
    "                                         center = True).mean().dropna(dim = \"time\", \n",
    "                                                                      how =  \"all\")\n",
    "                \n",
    "                tasmin.name = \"tasmin\"\n",
    "                tasmin.attrs[\"cell_methods\"] = \"time: minimum within days  time: minimum within years  time: mean over 30 years \" \n",
    "                \n",
    "                \n",
    "                \n",
    "                tasmin = tasmin.expand_dims(dim={\"model_member\" : 1})              \n",
    "\n",
    "         \n",
    "                outdata = xr.Dataset(data_vars = {\"tasmin\"     :       tasmin,\n",
    "                                                  \"model_member\": model_member},\n",
    "                                     attrs     = {\"scenario\"   :     scenario})\n",
    "\n",
    "                outdata.to_netcdf(path           = combined_file, \n",
    "                                  mode           =           'w', \n",
    "                                  format         =     \"NETCDF4\",\n",
    "                                  engine         =    \"h5netcdf\", #\n",
    "                                  unlimited_dims = \"model_member\",\n",
    "                                  encoding       = {\"tasmin\": {       \"dtype\": \"int16\", \n",
    "                                                               \"scale_factor\":    0.1,\n",
    "                                                                \"add_offset\" :    0.0,                                        \n",
    "                                                                 \"_FillValue\": -32767}})\n",
    "                \n",
    "                subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncatted -Oh -a _FillValue,lon,d,, \" + combined_file], \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "                subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncatted -Oh -a _FillValue,lat,d,, \" + combined_file], \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "                subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncatted -Oh -a _FillValue,time,d,, \" + combined_file],  \n",
    "                               shell = True, \n",
    "                               check = True)\n",
    "            # end check on avaiable variable\n",
    "        # end check on on avaiable member\n",
    "            \n",
    "    #end loop on model\n",
    "\n",
    "    print(\"# = = = = = = = = = = = = = = = = = = = = = = = = \") \n",
    "    \n",
    "    \n",
    "    model_member = xr.DataArray(data   = model_member_array,\n",
    "                                name   =  \"model_member\",\n",
    "                                dims   = [\"model_member\"],\n",
    "                                attrs  = {\"description\" : \"Model and Member Code\",\n",
    "                                          \"long_name\"   : \"Model and Member Code\",\n",
    "                                          \"code_to_name_lookup_table\":  model_member_key.values.tolist(),\n",
    "                                          \"comment1\"    : \"LUT Indexing Starts at 0\"})\n",
    "\n",
    "    model_member_ds = xr.Dataset(data_vars = {\"model_member\"          : model_member},\n",
    "                                 attrs     = {\"scenario\"   :     scenario})\n",
    "    \n",
    "    model_member_ds.to_netcdf(path           = \"./model_member.nc\", \n",
    "                               mode           =           'w', \n",
    "                               format         =     \"NETCDF4\",\n",
    "                               engine         =    \"h5netcdf\", #\n",
    "                               unlimited_dims = \"model_member\")  \n",
    "        \n",
    "    cdo_cat_command = \"nohup cdo --no_history -f nc4 -z zip_9 cat \"\n",
    "    nco_cat_command = \"nohup ncecat -M -u model_member \"\n",
    "    command_aggregate = cdo_cat_command +combined_wc_files + \" ./temp.nc\"     \n",
    "    print(\"# Final Aggregation\")\n",
    "    subprocess.run([\"rm -fr \" + final_merged_file + \" temp.nc temp2.nc\"], \n",
    "                   shell = True, \n",
    "                   check = True)    \n",
    "    subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && \" + command_aggregate], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# Files Concatenated\")\n",
    "\n",
    "    subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncks -C -O -x -v model_member ./temp.nc \" + final_merged_file], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# dimension dropped\")\n",
    "    subprocess.run([\"export HDF5_USE_FILE_LOCKING=FALSE && ncks -h -A ./model_member.nc \" + final_merged_file], \n",
    "                   shell = True, \n",
    "                   check = True)\n",
    "    print(\"# dimension swapped\")\n",
    "    subprocess.run([\"rm -fr  ./temp.nc ./temp2.nc ./ ./model_member.nc\" + combined_wc_files], \n",
    "                   shell = True, \n",
    "                   check = True) \n",
    "\n",
    "# end loop on scenario\n",
    "                \n",
    "print(\"# ================================================\")\n",
    "print(\"end processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c6cd9-732c-4dd0-a889-5ab5e1004edc",
   "metadata": {},
   "source": [
    "# Version History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9fa46-4b84-4a54-bfd7-417b132bd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#\n",
    "# Loading Version Information\n",
    "#\n",
    "\n",
    "%load_ext version_information\n",
    "%version_information version_information numpy, matplotlib, xarray, pandas, cartopy, metpy\n",
    "\n",
    "#\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dd8aa-ec04-4def-ab63-f5fc675e8cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# \" + str(model_member[0]).zfill(3) + \" \" + model + \" \" + member + \" \" + scenario + \" \" + inventory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
